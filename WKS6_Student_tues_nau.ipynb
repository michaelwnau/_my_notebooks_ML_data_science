{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/michaelwnau/ai_academy_notebooks/blob/main/WKS6_Student_tues_nau.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fv5JIEKAutY"
      },
      "source": [
        "# **Workshop 6**\n",
        "\n",
        "In this workshop, you'll be working with KNN and AdaBoost."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOlKo53VAutb"
      },
      "source": [
        "# 0) Loading Data & Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qe3MT9kcAutb"
      },
      "outputs": [],
      "source": [
        "from sklearn import metrics\n",
        "import numpy as np\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn import datasets\n",
        "\n",
        "# set a seed for reproducibility\n",
        "random_seed = 25\n",
        "np.random.seed(random_seed)\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKItD3N4Autc"
      },
      "source": [
        "# 1) Twitter Sentiment Analysis using KNN\n",
        "\n",
        "[Sentiment analysis](https://en.wikipedia.org/wiki/Sentiment_analysis) is the study of how we can systematically identify and quantify sentiment of a given segment of text. In this problem, you will be using the [Sentiment140](http://help.sentiment140.com/for-students/) dataset to build a classifier that will rate the sentiment of a string of text on a scale from 0 to 4.\n",
        "\n",
        "**WARNING:** This is *real* data from *real* people from Twitter. That means you might (and probably will) see some unscrupulous language when browsing the dataset. Don't browse with kids around!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3kY44GPAutc"
      },
      "source": [
        "Let's take a look at our data, and what attributes we have.\n",
        "\n",
        "* **polarity**: The assumed polarity of the tweet. For this subset, we're only considering positive and negative tweets, no neutrality.\n",
        "* **id**: The tweet ID.\n",
        "* **date**: The date the tweet was posted.\n",
        "* **query**: The search term used in order to find tweets of a certain topic.\n",
        "* **text**: The actual text of the tweet.\n",
        "\n",
        "For now, we only consider the **polarity** and **text** attributes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yOrKsGgQAutd"
      },
      "outputs": [],
      "source": [
        "train_data = pd.read_csv(\"./data/train_reduced.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FwDuW3YxAutd"
      },
      "outputs": [],
      "source": [
        "train_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QO_KqjH1Autd"
      },
      "outputs": [],
      "source": [
        "# Check our disribution of polarity\n",
        "# 4 means postive sentiment\n",
        "# 0 means negative sentiment\n",
        "train_data.polarity.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCl65rFaAute"
      },
      "source": [
        "## 1.1) Brief Introduction to tf-idf (Follow)\n",
        "In information retreival [tf-idf](https://en.wikipedia.org/wiki/Tf%E2%80%93idf) (*term frequency â€“ inverse document frequency*) is a metric that represents how \"important\" a word is to a corpus of text. While we won't go into detail about how it works, essentially all you need to know is that it balances two metrics.\n",
        "\n",
        "**Term Frequency**: Is exactly what one would expect, it is the the frequency at which a word is present in a corpus of text. A word with a higher term-frequency score appears much more in the corpus compared to one with a low term frequency.\n",
        "\n",
        "**Inverse Document Frequency**: If we only used term frequency, common words like \"the\" or \"and\" would have a high score, even though they don't give us that much information since they are present in every document. *Inverse Document Frequency* is a metric of how much \"information\" a word provides, and if a word is common or rare across all documents."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pH9OewOxAute"
      },
      "source": [
        "### tf-idf with sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k5vxkd3vAutf"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "corpus = [\n",
        "    'This is the first document.',\n",
        "    'This document is the second document.',\n",
        "    'And this is the third one.',\n",
        "    'Is this the first document?'\n",
        "]\n",
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(corpus)\n",
        "print(X.shape)\n",
        "print(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGBQVT4mAutf"
      },
      "source": [
        "The tf-idf vectorizer's `fit_transform` method returns a NxM matrix. `N` is the number of documents (sentences) you have in your corpus, and `M` is the number of unique words in your corpus. Item `n`x`m` is how important word `m` is to document `n`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "6TX-pN2sAutf"
      },
      "outputs": [],
      "source": [
        "# Printing out the tf-idf matrix\n",
        "np.set_printoptions(precision=4)\n",
        "print(X.toarray())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KQ5Z2ejIAutf"
      },
      "outputs": [],
      "source": [
        "# Notice that if we try and print X directly, we get an overview saying that X is a \"sparse matrix\".\n",
        "# In very large corpi with many unique words, a lot of row entries are going to consist of majority zeros\n",
        "# Thus numpy saves theses in a special compressed sparse format\n",
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h75dv9bQAutf"
      },
      "outputs": [],
      "source": [
        "# Next let's see what word each column corresponds to:\n",
        "vectorizer.get_feature_names_out()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zH6PsfCAutg"
      },
      "source": [
        "Let's look at the tf-idf vectors for two different documents.\n",
        "\n",
        "**Note**: `dic(zip(A, B))` in pyton makes a dictionary out of a list of keys (A) and values (B). This just makes it easier to view each term with it's corresponding TFIDF value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BUYX-UTKAutg"
      },
      "outputs": [],
      "source": [
        "print(corpus[0])\n",
        "dict(zip(vectorizer.get_feature_names_out(),X.toarray()[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ib4-XTBBAutg"
      },
      "outputs": [],
      "source": [
        "print(corpus[1])\n",
        "dict(zip(vectorizer.get_feature_names_out(),X.toarray()[1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZoIeE1iDAutg"
      },
      "source": [
        "Take a look at the tf-idf vectors for both of these sentences and answer the following questions:\n",
        "1. Why is the value for the term \"is\" higher in document1 than document2?\n",
        "2. Why is the value for the term \"document\" higher in document2 than document1?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_2Gy6ZLAutg"
      },
      "source": [
        "**Discuss Here**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGUOH1VfAutg"
      },
      "source": [
        "## 1.2) Model Design Discussion (Group)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tToc6024Autg"
      },
      "source": [
        "Now that you're aware of what tf-idf scores are, **discuss with your group on how you could use tf-idf to build a KNN classifier**:\n",
        "1. If the data objects (rows) each represent a tweet, what would the features (columns) of the dataset be?\n",
        "2. How would you represent a single tweet as a vector of numbers (values for each of the features)? What would it mean to have a value of 0 for a given feature? What about 0.4?\n",
        "3. What would it mean for two sentences to be \"nearest neighbors\"?\n",
        "4. Would you expect two near neighbors to have similar sentiment? Why or why not?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMLsGMjVAutg"
      },
      "source": [
        "**Discuss Here**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZVutqym5Auth"
      },
      "source": [
        "## 1.3) tf-idf on Twitter (Follow)\n",
        "\n",
        "Now, before we build a classifier, let's just try and see what the nearest neighbors of a specified message are."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kSv1n-mYAuth"
      },
      "outputs": [],
      "source": [
        "# Get our text\n",
        "corpus = train_data[\"text\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EGyjOsinAuth"
      },
      "outputs": [],
      "source": [
        "# Run our transform\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tf = TfidfVectorizer()\n",
        "tfidf_matrix = tf.fit_transform(corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wEY4GTzfAuth"
      },
      "outputs": [],
      "source": [
        "# Let's check the size of our matrix\n",
        "tfidf_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ad42C8qdAuth"
      },
      "source": [
        "Now, let's fit the nearest neighbors tree!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W8keZVJRAuth"
      },
      "outputs": [],
      "source": [
        "# Fit your KNN model\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "nbrs = NearestNeighbors(n_neighbors=5).fit(tfidf_matrix)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iv-YIastAuth"
      },
      "source": [
        "We can now run custom sentences and see what sentences in the corpus are \"closest\" to what we put in. Try a few and see what shows up! In addition to this, you can change the `n_neighbors` param and get more queries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hBTvJ5p-Auth"
      },
      "outputs": [],
      "source": [
        "# Test a tweet!\n",
        "test_docs = [\"I sure love paying my taxes!\"]\n",
        "test_docs = tf.transform(test_docs)\n",
        "distances, indicies = nbrs.kneighbors(test_docs)\n",
        "train_data.iloc[indicies[0]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3kiWLKQPAuth"
      },
      "source": [
        "Now discuss together:\n",
        "1. Try manually classifying the tweet \"Wow, this is so cool!\" What are the classes of the neighbors? How would a 5-NN classifier classify that tweet?\n",
        "2. Can you think of a tweet that might fool this classifier? For example, how would it do with sarcasm?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lI3um2MwAuth"
      },
      "source": [
        "## 1.4) Building and Evaluating the Classifier (Group)\n",
        "\n",
        "Now, your goal is to use the [KNeighborsClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html) in order to build an actual classifier for the sentiment dataset. Build the classifier with a `k=5`, and then evaluate it on the test data. Print the confusion matrix and a classification report, and interpret the evaluation metrics. Remember, a class label of `0` means a negative sentiment, and a class label of `4` means a positive sentiment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BiwWiR0RAuti"
      },
      "outputs": [],
      "source": [
        "test_data = pd.read_csv(\"./data/test_reduced.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NnnbkyLaAuti"
      },
      "outputs": [],
      "source": [
        "test_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xV65-q0AAuti"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jA9mMLmGAuti"
      },
      "outputs": [],
      "source": [
        "# Get your X features (text) and y labels (polarity) for the test set\n",
        "# Transform the X features into TFIDF vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pbgMo0vnAuti"
      },
      "outputs": [],
      "source": [
        "# Train your KNN model with k=5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3TtDOrbEAuti"
      },
      "outputs": [],
      "source": [
        "# Print a confusion matrix of the predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fvGR-Jl3Autm"
      },
      "outputs": [],
      "source": [
        "# Use the classification_report to report how well your model did\n",
        "print(classification_report(y_true,predictions))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZK9Z1lhIAutn"
      },
      "source": [
        "Now, discuss with your group about your results.\n",
        "1. How well do you think the classifier performed overall?\n",
        "2. Can you find some examples of test instances that were not accurately classified? Based on their nearest neighbots in the training dataset, why do you think they were hard to classify?\n",
        "3. We represented each tweet using TF-IDF, representing the frequency of individual words. What other types of features might be important for predicting the sentiment of a tweet?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJsL4xf0Autn"
      },
      "source": [
        "**Discuss your results here.** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KnUbfhoRAutn"
      },
      "source": [
        "# 2) AdaBoost\n",
        "\n",
        "In this exercise, you'll be learning how to use [AdaBoost](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html), as well as vizualize decision boundries."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHdNhc7vAutn"
      },
      "source": [
        "## 2.1) Using AdaBoost (Follow/Group)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kDXiHkUVAutn"
      },
      "outputs": [],
      "source": [
        "# Read the dataset and translate to pandas dataframe\n",
        "bc_sk = datasets.load_breast_cancer()\n",
        "# Note that the \"target\" attribute is malignant/benign, represented as an integer\n",
        "bc_data = pd.DataFrame(data= np.c_[bc_sk['data'], bc_sk['target']],columns= list(bc_sk['feature_names'])+['target'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wzyX9cRyAutn"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# The fraction of data that will be test data\n",
        "test_data_fraction = 0.10\n",
        "\n",
        "bc_features = bc_data.iloc[:,0:-1]\n",
        "bc_labels = bc_data[\"target\"]\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(bc_features, bc_labels, test_size=test_data_fraction,  random_state=random_seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TaBnI1sgAutn"
      },
      "source": [
        "First, let's have a baseline non-boosted decision tree to compare against."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PdTX5YWcAuto"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "gini_tree = DecisionTreeClassifier(criterion = \"gini\", random_state=random_seed).fit(X=X_train.values, y=Y_train.values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SFkfM1IiAuto"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "predicted_y = gini_tree.predict(X_test.values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LGPA3a-xAuto"
      },
      "outputs": [],
      "source": [
        "print(classification_report(Y_test, predicted_y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0lUP7XhxAuto"
      },
      "outputs": [],
      "source": [
        "confusion_matrix(Y_test, predicted_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cgbbYr2mAuto"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bs8PB8dxAuto"
      },
      "source": [
        "Now, let's get boosting. The default estimator for AdaBoost is a *decision stump*. (Remember: a decision stump is simply a decision tree with a height of 1)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u-yU4nn0Auto"
      },
      "outputs": [],
      "source": [
        "# Fit the Adaboost classifier "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c9rAbafDAuto"
      },
      "outputs": [],
      "source": [
        "# predict the labels for the test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ugqg5xu0Auto"
      },
      "outputs": [],
      "source": [
        "# print its performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fwYiB4dnAuto"
      },
      "outputs": [],
      "source": [
        "# print the confusion matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L11wCZqsAuto"
      },
      "source": [
        "As we can see, the boosted model performs better."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plWBsB0GAutp"
      },
      "source": [
        "Now, what happens when we put a more complex model into AdaBoost? Let's say, for this example, each component model is a full decision tree with no size limits.\n",
        "\n",
        "What do you expect will happen? Why? Discuss."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8E6vtRXAutp"
      },
      "source": [
        "**Discuss here**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7403DslaAutp"
      },
      "outputs": [],
      "source": [
        "# Try training a boosted model with full decision trees (no pruning)\n",
        "gini_tree = DecisionTreeClassifier(criterion = \"gini\", random_state=random_seed)\n",
        "bdt = AdaBoostClassifier(base_estimator=gini_tree,n_estimators=20,random_state=random_seed)\n",
        "bdt.fit(X_train,Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "guTwIM95Autp"
      },
      "outputs": [],
      "source": [
        "predicted_y = bdt.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7SH1nSeFAutp"
      },
      "outputs": [],
      "source": [
        "print(classification_report(Y_test, predicted_y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SXvlza7qAutp"
      },
      "outputs": [],
      "source": [
        "confusion_matrix(Y_test, predicted_y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNiXV7-jAutp"
      },
      "source": [
        "Were the results what you expected? If they weren't, why not? Discuss."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7rVhsinnAutp"
      },
      "source": [
        "**Discuss Here**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cIeZXDHQAutp"
      },
      "source": [
        "## 2.2) Visualizing Decision Boundries (Group)\n",
        "\n",
        "Now, we're going to peek under the hood and see the decision boundries of ensemble learners."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T04TJ0QQAutp"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "from sklearn.datasets import make_moons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "GdjGGUnnAutp"
      },
      "outputs": [],
      "source": [
        "# A nice noisy dataset that's not linearly separable\n",
        "X,y = make_moons(300, noise=0.13,random_state = random_seed)\n",
        "colors = {0:'red',1:\"blue\"}\n",
        "plt.scatter(X[:,0],X[:,1],c=np.vectorize(colors.get)(y))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ob9UPP5sAutp"
      },
      "source": [
        "You're given some code to calculate Adaboost by hand below, but for it to work, you need to complete the following helper functions.\n",
        "\n",
        "In `calculate_alpha`, you should calculate alpha for the round, based on the classifier's predictions and the weights of that round. The basic steps are:\n",
        "1. Calculate the **weighted** error $\\epsilon$ for the round by comparing those predictions to y. Remember, the error is the sum of the weights of misclassified instances.\n",
        "2. Calculate alpha using the following formula:\n",
        "\n",
        "$$\\alpha = 0.5*ln(\\frac{1 - \\epsilon}{\\epsilon})$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UOdzSPNLAutp"
      },
      "outputs": [],
      "source": [
        "def calculate_alpha(predictions, weights, y):\n",
        "    \"\"\"\n",
        "    Inputs:\n",
        "        predictions: the predictions (0 or 1) of the classifier in this round.\n",
        "        weights: the weights of each instance at the end of last round\n",
        "        y: the class labels (0 or 1) for the instances\n",
        "    Output: the alpha value for this round\n",
        "    \"\"\"\n",
        "    # BEGIN SOLUTION\n",
        "    return 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fmgWGCEbAutp"
      },
      "outputs": [],
      "source": [
        "# To test calculate_alpha, we need to make a decision tree and some starting weights\n",
        "dt = DecisionTreeClassifier(criterion = \"gini\", max_depth=1, random_state=123).fit(X, y)\n",
        "predictions = dt.predict(X)\n",
        "weights = np.repeat(1 / len(X), len(X))\n",
        "# Alpha should be ~0.84\n",
        "alpha = calculate_alpha(predictions, weights, y)\n",
        "np.testing.assert_almost_equal(alpha, 0.8416209435087314)\n",
        "alpha"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LHEW8Nn6Autq"
      },
      "source": [
        "Next you need to write a function that will update the weights for the adaboost classifier based on the alpha value. Remember:\n",
        "* Correctly classified instances have their weight decreased.\n",
        "* Incorrectly classified instances have their weight increased.\n",
        "\n",
        "The amount by which the weight changes is $e^\\alpha$.\n",
        "\n",
        "**Note**: You do not need to normalize the weights to sum to 1 - the code below will do that for you."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L-JPil5nAutq"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "def update_weights(predictions, weights, y, alpha):\n",
        "    \"\"\"\n",
        "    Inputs:\n",
        "        predictions: the predictions (0 or 1) of the classifier in this round.\n",
        "        weights: the weights at the end of the previous round for each instance\n",
        "        y: the class labels (0 or 1) for the instances\n",
        "        alpha: the alpha value for this round\n",
        "    Output: an array of updated weights for this round\n",
        "    \"\"\"\n",
        "    # BEGIN SOLUTION\n",
        "    return weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zh1iEDKhAutq"
      },
      "outputs": [],
      "source": [
        "weights = np.repeat(1 / len(X), len(X))\n",
        "new_weights = update_weights(predictions, weights, y, alpha) \n",
        "alpha = 0.8416209435087314\n",
        "print(new_weights)\n",
        "np.testing.assert_almost_equal(max(new_weights), 1/300*math.exp(alpha))\n",
        "np.testing.assert_almost_equal(min(new_weights), 1/300/math.exp(alpha))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-9OCFu5Autq"
      },
      "source": [
        "Here's our code for Adaboost. You don't have to modify it, just finish the functions above.\n",
        "\n",
        "Why are we implementing it by hand? This way we can keep track of which samples were chosen each round to visualize them.\n",
        "\n",
        "When you run the following code, you can see the alpha values for each round, changing as the weights, and therefore the samples, change."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "EfpqrdvlAutq"
      },
      "outputs": [],
      "source": [
        "# Let's do 20 rounds of adaboost\n",
        "rounds = 20\n",
        "# N is the length of training data\n",
        "N = len(X)\n",
        "# Each boostrapped sample will b size N/5\n",
        "sample_size = N // 5\n",
        "\n",
        "# Each round, keep track of:\n",
        "# Which instances (indices) were samples\n",
        "sample_indices = []\n",
        "# The classifier built on that sample\n",
        "dtrees = []\n",
        "# The alpha value for each that round\n",
        "alphas = []\n",
        "\n",
        "# Start our weights off each as 1/N\n",
        "weights = np.repeat(1 / N, N)\n",
        "\n",
        "for i in range(rounds):\n",
        "    indices = np.random.choice(range(N), sample_size, replace=True, p=weights)\n",
        "    sample_X = X[indices,:]\n",
        "    sample_y = y[indices]\n",
        "    # Train a simple decision tree on the sample\n",
        "    dt = DecisionTreeClassifier(criterion = \"gini\", max_depth=1).fit(sample_X, sample_y)\n",
        "    predictions = dt.predict(X)\n",
        "    \n",
        "    # Calculate alpha\n",
        "    alpha = calculate_alpha(predictions, weights, y)\n",
        "    print(f'Round {i} Alpha: {alpha}')\n",
        "    \n",
        "    # Update weights\n",
        "    weights = update_weights(predictions, weights, y, alpha)\n",
        "    weights /= sum(weights)\n",
        "    \n",
        "    sample_indices.append(indices)\n",
        "    alphas.append(alpha)\n",
        "    dtrees.append(dt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwHiOOfsAutq"
      },
      "outputs": [],
      "source": [
        "# This function makes predictions for a given list of X features by taking the weighted sum of\n",
        "# its constituent classifiers' predictions.\n",
        "def boosting_predict(X_test):\n",
        "    return np.mean([(dtrees[i].predict(X_test) - 0.5) * alphas[i] for i in range(len(dtrees))], axis=0) + 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "61Kf60XCAutq"
      },
      "outputs": [],
      "source": [
        "# Based on the image above, how should points (0, 0) and (1, 1) be classified?\n",
        "# Note that the output is continuous: > 0.5 means more likely to be 1.\n",
        "boosting_predict([[0, 0], [0, 1]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TqnYnrg3Autq"
      },
      "source": [
        "The following code will plot the predictions from individual rounds of adaboost. Note:\n",
        "* The background color indicates the prediction.\n",
        "* The faded dots were *not* sampled in this round (e.g. because of their low weights)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jnNjoSB_Autq"
      },
      "outputs": [],
      "source": [
        "# Here is a provided method that will plot the decision boundries of each stump\n",
        "\n",
        "def plot_predictions(pred_function, sample_indices, subplot=plt, continuous=False):\n",
        "    plot_colors = \"br\"\n",
        "    plot_step = 0.02\n",
        "    class_names = \"AB\"\n",
        "\n",
        "    #\n",
        "\n",
        "    # Plot the decision boundaries\n",
        "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
        "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
        "    xx, yy = np.meshgrid(np.arange(x_min, x_max, plot_step),\n",
        "                         np.arange(y_min, y_max, plot_step))\n",
        "\n",
        "    Z = pred_function(np.c_[xx.ravel(), yy.ravel()])\n",
        "    Z = Z.reshape(xx.shape)\n",
        "    if not continuous:\n",
        "        Z = np.round(Z)\n",
        "        cs = subplot.contourf(xx, yy, Z, cmap=plt.cm.Paired)\n",
        "    else:\n",
        "        cs = subplot.contourf(xx, yy, Z)\n",
        "\n",
        "    # Plot the training points\n",
        "    for i, n, c in zip(range(2), class_names, plot_colors):\n",
        "        idx = np.where(y == i)\n",
        "        in_sample_idx = np.intersect1d(idx, sample_indices)\n",
        "        subplot.scatter(X[in_sample_idx, 0], X[in_sample_idx, 1],\n",
        "                    c=c, cmap=plt.cm.Paired,\n",
        "                    s=20, edgecolor='k',\n",
        "                    label=\"Class %s (Sampled)\" % n)\n",
        "        out_sample_idx = np.setdiff1d(idx, in_sample_idx)\n",
        "        subplot.scatter(X[out_sample_idx, 0], X[out_sample_idx, 1],\n",
        "                    c=c, cmap=plt.cm.Paired,\n",
        "                    s=20, edgecolor='k', alpha=0.1,\n",
        "                    label=\"Class %s (Not Sampled)\" % n)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzer31PmAutq"
      },
      "source": [
        "Now we plot the first 12 rounds of adaboost:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "EEBxb5c5Autq"
      },
      "outputs": [],
      "source": [
        "rows = 4\n",
        "cols = 3\n",
        "\n",
        "figure, axis = plt.subplots(rows, cols, figsize=(15, 10))\n",
        "figure.tight_layout()\n",
        "\n",
        "for i in range(rows):\n",
        "    for j in range(cols):\n",
        "        idx = i*rows + j\n",
        "        subplot = plot_predictions(dtrees[idx].predict, sample_indices[idx], axis[i,j])\n",
        "        axis[i,j].title.set_text(f'Round {idx}: Alpha = {alphas[idx]}')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YzJV5DIIAutr"
      },
      "source": [
        "Now answer the following questions:\n",
        "1. Which rounds are most important to the classification? What do they have in common?\n",
        "2. Do you notice any changes in the samples (and resulting classifiers) in later rounds of Adaboost?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUn8z_K-Autr"
      },
      "source": [
        "**Answer here**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-ANK4oWAutr"
      },
      "source": [
        "Finally, we can plot the whole adaboost classifier. Note the non-linear decision boundary.\n",
        "* The first plot shows the discrete boundary, comprised of all of the above weak classifiers.\n",
        "* The second plot shows the same prediction as a continuous boundary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I7R0YHb8Autr"
      },
      "outputs": [],
      "source": [
        "plot_predictions(boosting_predict, range(len(X)), plt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s7TyPKWPAutr"
      },
      "outputs": [],
      "source": [
        "plot_predictions(boosting_predict, range(len(X)), plt, continuous=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFwOWRteAutr"
      },
      "source": [
        "Now answer the following questions:\n",
        "1. How can Adaboost create a non-linear boundary to accurately classify this shape?\n",
        "2. Which areas of the plot is the classifier most certain about, or least certain?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnmpIgChAutr"
      },
      "source": [
        "**Answer Here**"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}